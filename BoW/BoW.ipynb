{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step:\n",
    "\n",
    "#### I. Building CodeBook\n",
    "1. Using sift to detect keypoints and extract feature descriptors of all image in training set\n",
    "2. Using K-means with number_of_cluster = 20.000\n",
    "\n",
    "#### II. Compute histogram vector (a 20.000-dimention vector for each image)\n",
    "1. With each input image, extract all feature descriptors\n",
    "2. Assign each descriptor vector into the centers\n",
    "3. make histogram of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train sets and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9144\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "# load feature\n",
    "with open('features.pkl', 'rb') as feature_file:\n",
    "    features = pickle.load(feature_file)\n",
    "\n",
    "features = features.reshape((features.shape[0], features.shape[2]))\n",
    "\"\"\"\n",
    "\n",
    "# load all image name\n",
    "images = glob.glob('dataset/101_ObjectCategories//*//*.jpg')\n",
    "images.sort()\n",
    "print(len(images))\n",
    "\n",
    "# set labels for each image\n",
    "targets = []\n",
    "for image in images:\n",
    "    targets.append(image.split(\"/\")[1])\n",
    "\n",
    "# split to train/test set\n",
    "num_db = 3\n",
    "for i in range(num_db):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(images, targets, test_size=0.2)\n",
    "    db_path = 'db/db%s'%(i+1)\n",
    "    if not os.path.exists(db_path):\n",
    "        os.makedirs(db_path)\n",
    "\n",
    "    with open(db_path+'/train.txt', mode='w') as train_file:\n",
    "        for file in X_train:\n",
    "            train_file.write(file)\n",
    "            train_file.write('\\n')\n",
    "\n",
    "    with open(db_path+'/lbtrain.txt', mode='w') as label_train_file:\n",
    "        for label in Y_train:\n",
    "            label_train_file.write(label)\n",
    "            label_train_file.write('\\n')\n",
    "\n",
    "    with open(db_path+'/test.txt', mode='w') as test_file:\n",
    "        for file in X_test:\n",
    "            test_file.write(file)\n",
    "            test_file.write('\\n')\n",
    "\n",
    "    with open(db_path+'/lbtest.txt', mode='w') as label_test_file:\n",
    "        for label in Y_test:\n",
    "            label_test_file.write(label)\n",
    "            label_test_file.write('\\n')\n",
    "\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import LIBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from LoadData import LoadData\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract feature descriptors in trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noneMulticoreFeatureDescripting(img_paths_list):\n",
    "\tall_keypoints = []\n",
    "\tall_descriptors = np.array([], dtype=np.float32).reshape(0,128)\n",
    "\tsift = cv2.xfeatures2d.SIFT_create()\n",
    "\ti = 1\n",
    "\tfor image_path in img_paths_list:\n",
    "\t\tprint(str(i), ' --- Processing on:', image_path)\n",
    "\t\ti = i + 1\n",
    "\t\timage = cv2.imread(image_path)\n",
    "\t\tgray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t# key_points = sift.detect(gray_img, None)\n",
    "\t\tkey_points, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "\t\tall_keypoints = all_keypoints + key_points\n",
    "\t\t# print('descriptors:\\n', descriptors)\n",
    "\t\t# all_descriptors = all_descriptors + descriptors\n",
    "\t\t# all_descriptors.append(descriptors)\n",
    "\t\t# print (all_descriptors.shape)\n",
    "\t\t# print ( descriptors.shape)\n",
    "\t\tall_descriptors = np.concatenate((all_descriptors, descriptors), axis=0)\n",
    "\treturn all_descriptors, all_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appying multicore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(img_paths_list, start_point, end_point, queue):\n",
    "\ti = start_point\n",
    "\tsift = cv2.xfeatures2d.SIFT_create()        \n",
    "\tall_keypoints = []\n",
    "\tall_descriptors = []\n",
    "\tif start_point <= len(img_paths_list) :\n",
    "\t\tif end_point <= len(img_paths_list): \n",
    "\t\t\tpath_list = img_paths_list[start_point:end_point]\n",
    "\t\telse:\n",
    "\t\t\tpath_list = img_paths_list[start_point:len(img_paths_list)]\n",
    "\telse:\n",
    "\t\tpath_list = []\n",
    "\n",
    "\tfor image_path in path_list:\n",
    "\t\tprint(str(i),'  --  ',image_path)\n",
    "\t\ti = i + 1\n",
    "\t\timage = cv2.imread(image_path)\n",
    "\t\tgray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t# key_points = sift.detect(gray_img, None)\n",
    "\t\tkey_points, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "\t\tall_keypoints = all_keypoints + key_points\n",
    "\t\tall_descriptors.append(descriptors)\n",
    "\tprint(\"Finish process in 1 core!\")\n",
    "\tqueue.put(all_descriptors)\n",
    "\n",
    "def multiprocessingFeatureDescripting():\n",
    "\t# multicores processing\n",
    "\tnum_of_cores = 32\n",
    "\tdistance = int(len(img['trainImage'])/num_of_cores)\n",
    "\tqueue = Queue()\n",
    "\tsimilarities = [Process(target=featureExtraction, args=(img['trainImage'], x*distance, (x+1)*distance, queue)) for x in range (0,num_of_cores+1)]\n",
    "\n",
    "\tfor similar in similarities:\n",
    "\t\tsimilar.start()\n",
    "\n",
    "\tresult = []\n",
    "\tprint('Appending in result!')\n",
    "\tfor similar in similarities:\n",
    "\t\tsimilar.join(10)\n",
    "\t\tresult.append(queue.get(True))\n",
    "\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Codeword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildingCodeWord():\n",
    "\timg_paths_list = img['trainImage']\n",
    "\tall_descriptor_vectors, all_keypoints = noneMulticoreFeatureDescripting(img_paths_list)\n",
    "\tprint('Number of descriptors: ',len(all_descriptor_vectors))\n",
    "\tprint(all_descriptor_vectors)\n",
    "\tprint('Finish extracting descriptors!')\n",
    "\t# Number of clusters\n",
    "\tkmeans = KMeans(n_clusters=20000)\n",
    "\t# Fitting the input data\n",
    "\tkmeans = kmeans.fit(np.array(all_descriptor_vectors))\n",
    "\n",
    "\t# Getting the cluster labels\n",
    "\tlabels = kmeans.predict(np.array(all_descriptor_vectors))\n",
    "\t# Centroid values\n",
    "\tcentroids = kmeans.cluster_centers_\n",
    "\tprint('Finish clustering')\n",
    "\t# Comparing with scikit-learn centroids\n",
    "\tprint(centroids) # From sci-kit learn\n",
    "\n",
    "\t# Write to file:\n",
    "\tdata_path = \"codeword\"\n",
    "\tif not os.path.exists(data_path):\n",
    "\t\tos.makedirs(data_path)\n",
    "\tcodewords_file_path = data_path + '/codewords.dat'   \n",
    "\twith open(codewords_file_path, mode='wb') as codeword_file:\n",
    "\t\t# for centroid in centroids:\n",
    "\t\t# \tcodeword_file.write(str(centroid))\n",
    "\t\t# \tcodeword_file.write('\\n')\n",
    "\t\t# np.save(codeword_file, centroids)\n",
    "\t\tpickle.dump(centroids, codeword_file)\n",
    "\n",
    "\tprint(\"Finish building codebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of dimentions = number of cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute histogram for an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_feature_extraction(centroids, image):\n",
    "    # inititalize sift detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    # read image and extract sift features descriptor:\n",
    "    image = cv2.imread(image_path)\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    key_points, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "    \n",
    "    # Initialize the historgram ( ~ feature vector)\n",
    "    # number_of_demention_of_histogram = len(centroids)\n",
    "    histogram = np.zeros(number_of_demention_of_histogram)\n",
    "    \n",
    "    for keypoint_descriptor in keypoint_descriptors:\n",
    "        print ('---------------')\n",
    "        print ('des_vector: ', keypoint_descriptor)\n",
    "        distances_array = []\n",
    "        i = 0\n",
    "        for centroid in centroids:\n",
    "        #     distance = distance.euclidean(a,vector)\n",
    "            # Euclidean computation\n",
    "            distance = np.linalg.norm(np.array(keypoint_descriptor)-np.array(centroid))\n",
    "            print(i, ',  ', distance)\n",
    "            i += 1\n",
    "        #     np.concatenate((distances_array, distance), axis=0)\n",
    "        #     distances_array.append(distance)\n",
    "            distances_array.append(distance)\n",
    "        print ('- feature_vector_length:  ', len(distances_array))\n",
    "        print('- distance array: ', distances_array)\n",
    "        print ('minpost: %i'%distances_array.index(min(distances_array)))\n",
    "        min_index = distances_array.index(min(distances_array))\n",
    "        histogram[min_index] += 1\n",
    "        print('histogram: ', histogram)\n",
    "    print('feature vector under histogram form: ', histogram)\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute all bow_feature_vector (histograms) from image set and add to list (for using purpose later with SVM classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 44.18101501  14.23808861   7.3192091  ...,  18.30872917   3.90270853\n",
      "    6.54583168]\n",
      " [ 26.20446396  28.44099808  30.0435009  ...,  20.65877533  22.01660156\n",
      "   20.33893967]\n",
      " [ 16.62963295   7.91505909   8.70709991 ...,  10.57439423   9.37574768\n",
      "   11.03869152]\n",
      " ..., \n",
      " [ 26.34394073  24.1885891   24.1035881  ...,  14.76890945  15.89593887\n",
      "   18.36178207]\n",
      " [ 18.51602364  20.86983299  25.46174431 ...,  11.50701809  15.48223877\n",
      "   17.26696968]\n",
      " [ 15.38855553  12.05156708  12.68083763 ...,   5.28268433   4.06098938\n",
      "   12.13243866]]\n",
      "9\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-84d1f428d3fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mimg_paths_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trainImage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimg_paths_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mall_descriptors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow_feature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-6c4fb1b808a2>\u001b[0m in \u001b[0;36mbow_feature_extraction\u001b[1;34m(centroids, image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbow_feature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# inititalize sift detector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0msift\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# read image and extract sift features descriptor:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "import _pickle as pickle\n",
    "from LoadData import LoadData\n",
    "# not finished yet\n",
    "# # load file pickle\n",
    "def compute_vectors_for_image_dataset:\n",
    "    with open('codeword/codewords.dat', 'rb') as handle:\n",
    "        centroids = pickle.load(handle)\n",
    "\n",
    "    print(centroids)    \n",
    "    print(len(centroids))\n",
    "    all_descriptors = []\n",
    "\n",
    "    # read image paths\n",
    "    img = LoadData().getImagePath('db1')\n",
    "    img_paths_list = [img['trainImage'][0],] # read all image path in train images set\n",
    "    for image_path in img_paths_list:\n",
    "        all_descriptors.append(bow_feature_extraction(centroids, image_path))\n",
    "\n",
    "    return all_descriptors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating feature vectors under Histogram form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of dimentions = number of cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_descriptor_1 = [1, 1, 1, 1]\n",
    "keypoint_descriptor_2 = [1, 1, 1, 2]\n",
    "keypoint_descriptor_3 = [2, 10, 7, 1]\n",
    "keypoint_descriptor_4 = [8,9,7,1]\n",
    "keypoint_descriptor_5 = [9, 1, 1, 5]\n",
    "keypoint_descriptor_6 = [9, 1, 1, 9]\n",
    "\n",
    "\n",
    "c1 = [1, 1, 2, 1]\n",
    "c2 = [2,3,4,5]\n",
    "c3 = [8,9,7,1]\n",
    "c4 = [2,10,10,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = []\n",
    "centroids.append(c1)\n",
    "centroids.append(c2)\n",
    "centroids.append(c3)\n",
    "centroids.append(c4)\n",
    "\n",
    "\n",
    "keypoint_descriptors = []\n",
    "keypoint_descriptors.append(keypoint_descriptor_1)\n",
    "keypoint_descriptors.append(keypoint_descriptor_2)\n",
    "keypoint_descriptors.append(keypoint_descriptor_3)\n",
    "keypoint_descriptors.append(keypoint_descriptor_4)\n",
    "keypoint_descriptors.append(keypoint_descriptor_5)\n",
    "keypoint_descriptors.append(keypoint_descriptor_6)\n",
    "# np.concatenate((d,b),sxi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 2, 1], [2, 3, 4, 5], [8, 9, 7, 1], [2, 10, 10, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_feature_extraction(centroids, image):\n",
    "    # inititalize sift detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    # read image and extract sift features descriptor:\n",
    "    image = cv2.imread(image_path)\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    key_points, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "    \n",
    "    # Initialize the historgram ( ~ feature vector)\n",
    "    # number_of_demention_of_histogram = len(centroids)\n",
    "    histogram = np.zeros(number_of_demention_of_histogram)\n",
    "    \n",
    "    for keypoint_descriptor in keypoint_descriptors:\n",
    "        print ('---------------')\n",
    "        print ('des_vector: ', keypoint_descriptor)\n",
    "        distances_array = []\n",
    "        i = 0\n",
    "        for centroid in centroids:\n",
    "        #     distance = distance.euclidean(a,vector)\n",
    "            # Euclidean computation\n",
    "            distance = np.linalg.norm(np.array(keypoint_descriptor)-np.array(centroid))\n",
    "            print(i, ',  ', distance)\n",
    "            i += 1\n",
    "        #     np.concatenate((distances_array, distance), axis=0)\n",
    "        #     distances_array.append(distance)\n",
    "            distances_array.append(distance)\n",
    "        print ('- feature_vector_length:  ', len(distances_array))\n",
    "        print('- distance array: ', distances_array)\n",
    "        print ('minpost: %i'%distances_array.index(min(distances_array)))\n",
    "        min_index = distances_array.index(min(distances_array))\n",
    "        histogram[min_index] += 1\n",
    "        print('histogram: ', histogram)\n",
    "    print('feature vector under histogram form: ', histogram)\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
